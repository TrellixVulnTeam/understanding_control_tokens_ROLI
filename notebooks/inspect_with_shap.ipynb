{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, BartForConditionalGeneration, BartTokenizer\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<class 'torch.cuda.device'>\n",
      "1\n",
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "GPU = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    print(torch.cuda.current_device())\n",
    "    print(torch.cuda.device)\n",
    "    torch.cuda.device = GPU\n",
    "    print(torch.cuda.device)\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/srv/scratch6/kew/ats/muss/resources/models/muss_en_mined_hf\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "# model = BartForConditionalGeneration.from_pretrained(model_path, output_attentions=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "\n",
    "model = model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is very hard to understand..\n",
      "This is very hard to understand..\n",
      "This is very hard to understand..\n",
      "This is very hard to understand..\n",
      "This is very hard to understand..\n",
      "This is very hard to understand..\n"
     ]
    }
   ],
   "source": [
    "# modifying the value of a single special token\n",
    "sentences = [\n",
    "    \"<DEPENDENCYTREEDEPTHRATIO_0.0> <WORDRANKRATIO_0.75> <REPLACEONLYLEVENSHTEIN_0.65> <LENGTHRATIO_0.75> This is extremely hard to comprehend.\",\n",
    "    \"<DEPENDENCYTREEDEPTHRATIO_0.2> <WORDRANKRATIO_0.75> <REPLACEONLYLEVENSHTEIN_0.65> <LENGTHRATIO_0.75> This is extremely hard to comprehend.\",\n",
    "    \"<DEPENDENCYTREEDEPTHRATIO_0.4> <WORDRANKRATIO_0.75> <REPLACEONLYLEVENSHTEIN_0.65> <LENGTHRATIO_0.75> This is extremely hard to comprehend.\",\n",
    "    \"<DEPENDENCYTREEDEPTHRATIO_0.6> <WORDRANKRATIO_0.75> <REPLACEONLYLEVENSHTEIN_0.65> <LENGTHRATIO_0.75> This is extremely hard to comprehend.\",\n",
    "    \"<DEPENDENCYTREEDEPTHRATIO_0.8> <WORDRANKRATIO_0.75> <REPLACEONLYLEVENSHTEIN_0.65> <LENGTHRATIO_0.75> This is extremely hard to comprehend.\",\n",
    "    \"<DEPENDENCYTREEDEPTHRATIO_1.0> <WORDRANKRATIO_0.75> <REPLACEONLYLEVENSHTEIN_0.65> <LENGTHRATIO_0.75> This is extremely hard to comprehend.\",\n",
    "]\n",
    "batch = tokenizer(sentences, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "generated_ids = model.generate(batch[\"input_ids\"].to(model.device))\n",
    "generated_sents = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "for s in generated_sents:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap: https://shap.readthedocs.io/en/latest/example_notebooks/text_examples/translation/Machine%20Translation%20Explanations.html\n",
    "explainer = shap.Explainer(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ea77730e92406194e72c9596ff8225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap_values = explainer(sentences[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.plots.text(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctrl_tokens",
   "language": "python",
   "name": "ctrl_tokens"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
